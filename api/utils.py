import os
from langchain.chains.llm import LLMChain
from langchain_core.prompts import PromptTemplate
from langchain.vectorstores.pinecone import Pinecone 
from langchain_openai import OpenAIEmbeddings 
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.chains.combine_documents.reduce import ReduceDocumentsChain
from langchain.chains.combine_documents.map_reduce import MapReduceDocumentsChain
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv() 

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
INDEX_NAME = "langchainvector"

llm = ChatOpenAI(temperature=0.0, api_key=OPENAI_API_KEY, max_tokens=4096, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])

openai_embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)


class DocumentProcessor:
    def __init__(self, pdf_file_path):
        self.loader = PyPDFLoader(pdf_file_path)
        self.file_content = self.loader.load()
        

    def split_text(self,expert_type):
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50, length_function=len)
        text_chunks = text_splitter.split_documents(self.file_content)
        
        if text_chunks:
            if expert_type == 'parenting_coach':
                Pinecone.from_texts([t.page_content for t in text_chunks], openai_embeddings, index_name=INDEX_NAME, namespace='Parenting_coach')
            elif expert_type == 'life_coaching':
                Pinecone.from_texts([t.page_content for t in text_chunks], openai_embeddings, index_name=INDEX_NAME, namespace='Life_coaching_expert')
            elif expert_type == 'business_idea':
                Pinecone.from_texts([t.page_content for t in text_chunks], openai_embeddings, index_name=INDEX_NAME, namespace='Business_idea_expert')
            elif expert_type == 'career':
                Pinecone.from_texts([t.page_content for t in text_chunks], openai_embeddings, index_name=INDEX_NAME, namespace='Career_expert')

        else :
            print("Please enter the valid expert type")


def tasks_extractor(txt):
    reduce_template = """The following answer id generated by experts who helps user to achieve their goal:
    {doc_summaries}
    you need to create a task list from the given text so that user can work accordingly. Make sure you provide actionable tasks in the numbers, and all task should be separate with comma. 
    Answer:"""
    
    reduce_prompt = PromptTemplate.from_template(reduce_template)
    map_chain = LLMChain(llm=llm, prompt=reduce_prompt)

    reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)
    combine_documents_chain = StuffDocumentsChain(
            llm_chain=reduce_chain, document_variable_name="doc_summaries"
        )

    reduce_documents_chain = ReduceDocumentsChain(      
            combine_documents_chain=combine_documents_chain,
            collapse_documents_chain=combine_documents_chain,
            token_max=4000,
        )

    text_splitter = RecursiveCharacterTextSplitter(separators=["\n\n", "\n"], chunk_size=5000, chunk_overlap=350)
    docs = text_splitter.create_documents([txt])
    map_reduce_chain = MapReduceDocumentsChain(
            llm_chain=map_chain,
            reduce_documents_chain=reduce_documents_chain,
            document_variable_name="doc_summaries",
            return_intermediate_steps=False,
        )
    
    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)
    split_docs = text_splitter.split_documents(docs)
    task_list = map_reduce_chain.run(split_docs)

    return task_list


    